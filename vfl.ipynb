{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cvxpy as cp\n",
    "\n",
    "from models import VFL\n",
    "from methods import TrackingADMM, DPMM, APAPC\n",
    "from utils import plot_logs, plot_logs_pd, plot_comparison_iteration, plot_comparison_time\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "myparams = {\n",
    "    'text.usetex': True,\n",
    "    'text.latex.preamble': r'\\usepackage{amsfonts}',\n",
    "    'font.family': 'Djvu Serif',\n",
    "    'font.size': 16,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.1,\n",
    "    'lines.linewidth': 2\n",
    "}\n",
    "\n",
    "plt.rcParams.update(myparams)\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Experiment - VFL (Vertical Federative Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of VFL the data is partinioned by features, differing from usual (horizontal) federated learning, where the data is partitioned by samples.\n",
    "\n",
    "Let $\\mathbf{F}$ be the matrix of features, splitted vertically between compute nodes into submatrices $\\mathbf{F}_i$, so that each node possess its own subset of features for all data samples. \n",
    "Let $l$ denote the vector of labels, and let $w_i$ be the vector of model parameters owned by the $i$-th node.\n",
    "VFL problem formulates as\n",
    "\n",
    "$$ \\min_{w_1,\\ldots,w_n \\in \\mathbb{R}^d} \\ell(z, l) + \\sum_{i=1}^n r_i(w_i) \\quad \\text{s.t.} \\quad \\sum_{i=1}^n \\mathbf{F}_i w_i = z $$\n",
    "\n",
    "where $\\ell$ is a loss function, and $r_i$ are regulizers.\n",
    "Constraints are coupled constraints, and the objective is separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels are stored in the first device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conduct experiments on the linear regression problem with MSE loss and L2 regularizer:\n",
    "\n",
    "$$ \\ell(z, l) = \\frac{1}{2} \\| z - l \\|_2^2 $$\n",
    "$$ r_i(w_i) = \\lambda \\| w_i \\|_2^2 $$\n",
    "\n",
    "Thus the problem is\n",
    "\n",
    "$$ \\min_{w \\in \\mathbb{R}^{nd}} F(w) = \\frac{1}{2} \\| \\mathbf{F}w - l \\|_2^2 + \\lambda \\| w \\|_2^2 = $$\n",
    "$$ = \\frac{1}{2} \\| \\sum\\limits_{i=1}^{n} \\mathbf{F}_i w_i - l \\|_2^2 + \\lambda \\sum\\limits_{i=1}^{n} \\| w_i \\|_2^2 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_1 = \\begin{pmatrix} w_1 \\\\ z \\end{pmatrix}, \\quad x_2 = w_2, \\quad \\ldots, \\quad x_n = w_n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f_1(x_1) = f_1(w_1, z) = \\frac{1}{2}\\|z - l\\|_2^2 + \\lambda \\|w_1\\|_2^2 $$\n",
    "$$ f_i(x_i) = f_i(w_i) = \\lambda \\|w_i\\|_2^2, \\quad i = 2, \\ldots, n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A_1 = \\begin{pmatrix} \\mathbf{F}_1 & -\\mathbf{I} \\end{pmatrix}, \\qquad A_1 x_1 = \\mathbf{F}_1 w_1 - z $$\n",
    "$$ A_i = \\mathbf{F}_i, \\quad i = 2, \\ldots, n, \\qquad \\sum\\limits_{i=1}^{n} A_i x_i = \\sum\\limits_{i=1}^{n} \\mathbf{F}_i w_i - z $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get the problem in our notation\n",
    "\n",
    "$$ \\min_{x} F(x) = \\sum\\limits_{i=1}^{n} f_i(x_i) $$\n",
    "$$ \\textrm{s.t.} \\quad \\sum\\limits_{i=1}^{n} A_i x_i = 0 $$ \n",
    "\n",
    "While the right-hand side\n",
    "\n",
    "$$ b_i = 0, \\quad i = 1, \\ldots, n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `mushrooms` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "train_size = 0.05 # 8124 // 20 = 406\n",
    "NUM_STEPS = 100\n",
    "NUM_NODES = 4 # 14 # 112 % 14 = 0\n",
    "TITLE = 'mushrooms'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-3, title=TITLE, train_size=train_size, graph=graph, edge_prob=0.5, gossip=False,\n",
    "            labels_distribution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or `a9a` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "train_size = 0.02 # 32561 // 50 = 651\n",
    "NUM_STEPS = 1000\n",
    "NUM_NODES = 3 # 123 % 3 = 0\n",
    "TITLE = 'a9a'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-2, title=TITLE, train_size=train_size, graph=graph, edge_prob=0.5, gossip=False,\n",
    "            labels_distribution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `w8a` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "train_size = 0.01 # 49749 // 100 = 497\n",
    "NUM_STEPS = 1000\n",
    "NUM_NODES = 10 # 300 % 10 = 30\n",
    "TITLE = 'w8a'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-3, title=TITLE, train_size=train_size, graph=graph, edge_prob=0.5, gossip=True,\n",
    "            labels_distribution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can use synthetic linear regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "NUM_STEPS = 1000\n",
    "NUM_NODES = 10\n",
    "TITLE = 'synthetic'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-3, title=TITLE, graph=graph, edge_prob=0.5, gossip=False, labels_distribution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking-ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_err, F_err, cons_err, ts = TrackingADMM(num_steps=NUM_STEPS, model=model)\n",
    "plot_logs(x_err, F_err, cons_err, title='Tracking-ADMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_err, F_err, cons_err, ts = DPMM(num_steps=NUM_STEPS, model=model)\n",
    "plot_logs(x_err, F_err, cons_err, title='DPMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APAPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_err, F_err, cons_err, primal_dual_err, ts = APAPC(num_steps=NUM_STEPS, model=model)\n",
    "plot_logs_pd(x_err, F_err, cons_err, primal_dual_err, title='APAPC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Tracking-ADMM', 'DPMM', 'APAPC']\n",
    "methods = [TrackingADMM, DPMM, APAPC]\n",
    "results = {title: {} for title in titles}\n",
    "\n",
    "for (title, method) in zip(titles, methods):\n",
    "    result = method(num_steps=NUM_STEPS, model=model)\n",
    "    results[title]['x_err'] = result[1]\n",
    "    results[title]['F_err'] = result[2]\n",
    "    results[title]['cons_err'] = result[3]\n",
    "    results[title]['ts'] = result[-1]\n",
    "\n",
    "plot_comparison_iteration(results)\n",
    "plot_comparison_time(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels are distributed between devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_1 = \\begin{pmatrix} w_1 \\\\ z_1 \\end{pmatrix}, \\quad x_2 = \\begin{pmatrix} w_2 \\\\ z_2 \\end{pmatrix}, \\quad \\ldots, \\quad x_n = \\begin{pmatrix} w_n \\\\ z_n \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f_i(x_i) = f_i(w_i, z_i) = \\frac{1}{2}\\|z_i - l_i\\|_2^2 + \\lambda \\|w_i\\|_2^2, \\quad i = 1, \\ldots, n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A_i = \\begin{pmatrix} \\mathbf{F}_i & \\mathbf{C}_i \\end{pmatrix}, \\qquad \\mathbf{C}_i = \\begin{pmatrix} \\mathbf{O}_{\\mathrm{dim}(z_i)} \\\\ \\vdots \\\\ -\\mathbf{I}_{\\mathrm{dim}(z_i)} \\\\ \\vdots \\\\ \\mathbf{O}_{\\mathrm{dim}(z_i)} \\end{pmatrix}, \\quad i = 1, \\ldots, n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `mushrooms` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "train_size = 0.05 # 8124 // 20 = 406\n",
    "NUM_STEPS = 100\n",
    "NUM_NODES = 14 # 112 % 14 = 0\n",
    "TITLE = 'mushrooms'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-3, title=TITLE, train_size=train_size, graph=graph, edge_prob=0.5, gossip=False,\n",
    "            labels_distribution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or `a9a` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "train_size = 0.02 # 32561 // 50 = 651\n",
    "NUM_STEPS = 1000\n",
    "NUM_NODES = 3 # 123 % 3 = 0\n",
    "TITLE = 'a9a'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-2, title=TITLE, train_size=train_size, graph=graph, edge_prob=0.5, gossip=False,\n",
    "            labels_distribution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `w8a` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "train_size = 0.01 # 49749 // 100 = 497\n",
    "NUM_STEPS = 1000\n",
    "NUM_NODES = 10 # 300 % 10 = 30\n",
    "TITLE = 'w8a'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-3, title=TITLE, train_size=train_size, graph=graph, edge_prob=0.5, gossip=True,\n",
    "            labels_distribution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can use synthetic linear regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(307)\n",
    "\n",
    "NUM_STEPS = 1000\n",
    "NUM_NODES = 10\n",
    "TITLE = 'synthetic'\n",
    "graph = 'erdos-renyi'\n",
    "\n",
    "model = VFL(NUM_NODES, lmbd=1e-3, title=TITLE, graph=graph, edge_prob=0.5, gossip=False, labels_distribution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking-ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_err, F_err, cons_err, ts = TrackingADMM(num_steps=NUM_STEPS, model=model)\n",
    "plot_logs(x_err, F_err, cons_err, title='Tracking-ADMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_err, F_err, cons_err, ts = DPMM(num_steps=NUM_STEPS, model=model)\n",
    "plot_logs(x_err, F_err, cons_err, title='DPMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APAPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_err, F_err, cons_err, primal_dual_err, ts = APAPC(num_steps=NUM_STEPS, model=model)\n",
    "plot_logs_pd(x_err, F_err, cons_err, primal_dual_err, title='APAPC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Tracking-ADMM', 'DPMM', 'APAPC']\n",
    "methods = [TrackingADMM, DPMM, APAPC]\n",
    "results = {title: {} for title in titles}\n",
    "\n",
    "for (title, method) in zip(titles, methods):\n",
    "    result = method(num_steps=NUM_STEPS, model=model)\n",
    "    results[title]['x_err'] = result[1]\n",
    "    results[title]['F_err'] = result[2]\n",
    "    results[title]['cons_err'] = result[3]\n",
    "    results[title]['ts'] = result[-1]\n",
    "\n",
    "plot_comparison_iteration(results)\n",
    "plot_comparison_time(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
